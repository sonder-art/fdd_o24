{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediccion de Default en Prestamos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este proyecto utilizaremos un sample de los datos de Lending Club. La idea es predecir si cierto usuario cometera Default basado en informacion que la plataforma recolecta. Esto nos ayudara a mejorar la metodologia/pipeline de prestamo.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripcion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Contiene los prestamos de esta plataforma:\n",
    "\n",
    "    periodo 2007-2017Q3.\n",
    "    887mil observaciones, sample de 100mil\n",
    "    150 variables\n",
    "    Target: loan status\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar un ETL y un EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Limpia los datos de tal manera que al final del ETL queden en formato `tidy`.\n",
    "1. Asegurate de cargar y leer los datos\n",
    "2. Crea una tabla donde se guarde el nombre de la columna y el tipo de dato: (`column_name`,   `type`).\n",
    "3. Asegurate de pensar cual es el tipo de dato correcto. Porque elejiste strig/object o float o int?. No hay respuestas incorrectas como tal, pero tienes que justificar tu decision.\n",
    "4. Maneja missings o nans de la manera adecuada. Justifica cada decision\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Preparar lo datos para un pipeline de datos\n",
    "1. Quitar columnas inservibles \n",
    "2. Imputar valores\n",
    "3. Mantener replicabildiad y reproducibilidad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No olvides anotar tus justificaciones en celdas para recordar cuando te toque explicarlo.** Puedes agregar el numero de celdas que necesites para poner tu explicacion y el codigo, solo manten la estructura."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vas a obtener 2 errores, solucionalo con los visto en clase.  \n",
    "Tip: Se arreglan con argumentos adicionales de la funcion `read_csv`  \n",
    "Documentacion: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37450/188983864.py:1: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  loans = pd.read_csv('https://github.com/sonder-art/fdd_prim_2023/blob/main/codigo/pandas/LoansData_sample.csv.gz?raw=true', compression='gzip')\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv('https://github.com/sonder-art/fdd_prim_2023/blob/main/codigo/pandas/LoansData_sample.csv.gz?raw=true', compression='gzip')\n",
    "\n",
    "df_loans = pd.DataFrame(loans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla (column_name, type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisa el metodo pd.DataFrame.dtypes. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dtype('int64') dtype('float64') dtype('O')]\n"
     ]
    }
   ],
   "source": [
    "column_types = df_loans.dtypes.unique()\n",
    "print(column_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar descripcion de columnas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente tabla tiene una descripcion del significado de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "datos_dict = pd.read_excel(\n",
    "    'https://resources.lendingclub.com/LCDataDictionary.xlsx')\n",
    "datos_dict.columns = ['feature', 'description']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acc_now_delinq</td>\n",
       "      <td>The number of accounts on which the borrower i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acc_open_past_24mths</td>\n",
       "      <td>Number of trades opened in past 24 months.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>addr_state</td>\n",
       "      <td>The state provided by the borrower in the loan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all_util</td>\n",
       "      <td>Balance to credit limit on all trades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>The self-reported annual income provided by th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>settlement_amount</td>\n",
       "      <td>The loan amount that the borrower has agreed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>settlement_percentage</td>\n",
       "      <td>The settlement amount as a percentage of the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>settlement_term</td>\n",
       "      <td>The number of months that the borrower will be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>NaN</td>\n",
       "      <td>* Employer Title replaces Employer Name for al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature                                        description\n",
       "0           acc_now_delinq  The number of accounts on which the borrower i...\n",
       "1     acc_open_past_24mths         Number of trades opened in past 24 months.\n",
       "2               addr_state  The state provided by the borrower in the loan...\n",
       "3                 all_util              Balance to credit limit on all trades\n",
       "4               annual_inc  The self-reported annual income provided by th...\n",
       "..                     ...                                                ...\n",
       "148      settlement_amount  The loan amount that the borrower has agreed t...\n",
       "149  settlement_percentage  The settlement amount as a percentage of the p...\n",
       "150        settlement_term  The number of months that the borrower will be...\n",
       "151                    NaN                                                NaN\n",
       "152                    NaN  * Employer Title replaces Employer Name for al...\n",
       "\n",
       "[153 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea codigo para **guardar** y **cargar** el DataFrame de `datos_dict` creada en las celdas anteriores en formato **pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codigo guardar\n",
    "with open('datos_dictP.pkl', 'wb') as f:\n",
    "    pickle.dump(datos_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acc_now_delinq</td>\n",
       "      <td>The number of accounts on which the borrower i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acc_open_past_24mths</td>\n",
       "      <td>Number of trades opened in past 24 months.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>addr_state</td>\n",
       "      <td>The state provided by the borrower in the loan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all_util</td>\n",
       "      <td>Balance to credit limit on all trades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>The self-reported annual income provided by th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>settlement_amount</td>\n",
       "      <td>The loan amount that the borrower has agreed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>settlement_percentage</td>\n",
       "      <td>The settlement amount as a percentage of the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>settlement_term</td>\n",
       "      <td>The number of months that the borrower will be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>NaN</td>\n",
       "      <td>* Employer Title replaces Employer Name for al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature                                        description\n",
       "0           acc_now_delinq  The number of accounts on which the borrower i...\n",
       "1     acc_open_past_24mths         Number of trades opened in past 24 months.\n",
       "2               addr_state  The state provided by the borrower in the loan...\n",
       "3                 all_util              Balance to credit limit on all trades\n",
       "4               annual_inc  The self-reported annual income provided by th...\n",
       "..                     ...                                                ...\n",
       "148      settlement_amount  The loan amount that the borrower has agreed t...\n",
       "149  settlement_percentage  The settlement amount as a percentage of the p...\n",
       "150        settlement_term  The number of months that the borrower will be...\n",
       "151                    NaN                                                NaN\n",
       "152                    NaN  * Employer Title replaces Employer Name for al...\n",
       "\n",
       "[153 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Codigo para cargar\n",
    "with open('datos_dict.pkl', 'rb') as f:\n",
    "    datos_dictP = pickle.load(f)\n",
    "    \n",
    "datos_dictP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realiza las transformaciones o casteos (casting) que creas necesarios a tus datos de tal manera que el typo de dato sea adecuado. Al terminar recrea la tabla `column_types` con los nuevos tipos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No olvides anotar tus justificaciones para recordar cuando te toque explicarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing column 'Unnamed: 0':\n",
      "  - Min value: 0\n",
      "  - Max value: 99999\n",
      "  - Contains NaNs: No\n",
      "  - Column 'Unnamed: 0' is within int32 range. It can be safely cast to int32.\n",
      "  - Column 'Unnamed: 0' has been cast to int32.\n"
     ]
    }
   ],
   "source": [
    "# Manejos de tipos 1\n",
    "# Tu codigo aqui\n",
    "\n",
    "int64_columns = [col for col in loans.columns if loans[col].dtype == 'int64']\n",
    "\n",
    "def change_cast_to_int32(df, columns):\n",
    "    int32_min, int32_max = -2**31, 2**31 - 1  # Range of int32\n",
    "    \n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Column '{col}' does not exist in the DataFrame.\")\n",
    "            continue\n",
    "\n",
    "        # Check if column is numeric\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            print(f\"Column '{col}' is not numeric, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Check for NaNs and analyze range\n",
    "        has_nan = df[col].isna().any()\n",
    "        min_val = df[col].min()\n",
    "        max_val = df[col].max()\n",
    "\n",
    "        print(f\"\\nAnalyzing column '{col}':\")\n",
    "        print(f\"  - Min value: {min_val}\")\n",
    "        print(f\"  - Max value: {max_val}\")\n",
    "        print(f\"  - Contains NaNs: {'Yes' if has_nan else 'No'}\")\n",
    "\n",
    "        # Evaluate if casting to int32 is safe\n",
    "        if has_nan:\n",
    "            print(f\"  - Column '{col}' has NaN values, conversion to int32 will not be possible without handling them.\")\n",
    "        elif min_val >= int32_min and max_val <= int32_max:\n",
    "            print(f\"  - Column '{col}' is within int32 range. It can be safely cast to int32.\")\n",
    "            # Optional: Cast to int32 if suitable\n",
    "            df[col] = df[col].astype('int32')\n",
    "            print(f\"  - Column '{col}' has been cast to int32.\")\n",
    "        else:\n",
    "            print(f\"  - Column '{col}' has values outside int32 range. Conversion to int32 is not safe.\")\n",
    "            \n",
    "change_cast_to_int32(loans, int64_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing column 'annual_inc_joint':\n",
      "  - Min value: nan\n",
      "  - Max value: nan\n",
      "  - Contains NaNs: Yes\n",
      "  - Column 'annual_inc_joint' has values outside the float32 range. Conversion to float32 is not safe.\n",
      "\n",
      "Analyzing column 'dti_joint':\n",
      "  - Min value: nan\n",
      "  - Max value: nan\n",
      "  - Contains NaNs: Yes\n",
      "  - Column 'dti_joint' has values outside the float32 range. Conversion to float32 is not safe.\n",
      "\n",
      "Analyzing column 'total_bal_il':\n",
      "  - Min value: nan\n",
      "  - Max value: nan\n",
      "  - Contains NaNs: Yes\n",
      "  - Column 'total_bal_il' has values outside the float32 range. Conversion to float32 is not safe.\n",
      "\n",
      "Analyzing column 'il_util':\n",
      "  - Min value: nan\n",
      "  - Max value: nan\n",
      "  - Contains NaNs: Yes\n",
      "  - Column 'il_util' has values outside the float32 range. Conversion to float32 is not safe.\n",
      "\n",
      "Analyzing column 'max_bal_bc':\n",
      "  - Min value: nan\n",
      "  - Max value: nan\n",
      "  - Contains NaNs: Yes\n",
      "  - Column 'max_bal_bc' has values outside the float32 range. Conversion to float32 is not safe.\n",
      "\n",
      "Analyzing column 'all_util':\n",
      "  - Min value: nan\n",
      "  - Max value: nan\n",
      "  - Contains NaNs: Yes\n",
      "  - Column 'all_util' has values outside the float32 range. Conversion to float32 is not safe.\n",
      "\n",
      "Analyzing column 'revol_bal_joint':\n",
      "  - Min value: nan\n",
      "  - Max value: nan\n",
      "  - Contains NaNs: Yes\n",
      "  - Column 'revol_bal_joint' has values outside the float32 range. Conversion to float32 is not safe.\n",
      "\n",
      "Analyzing column 'sec_app_revol_util':\n",
      "  - Min value: nan\n",
      "  - Max value: nan\n",
      "  - Contains NaNs: Yes\n",
      "  - Column 'sec_app_revol_util' has values outside the float32 range. Conversion to float32 is not safe.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manejos de tipos 2\n",
    "# Tu codigo aqui\n",
    "\n",
    "float64_columns = [col for col in loans.columns if loans[col].dtype == 'float64']\n",
    "\n",
    "def cast_float32(df, columns):\n",
    "    float32_min, float32_max = np.finfo(np.float32).min, np.finfo(np.float32).max  # Range of float32\n",
    "    \n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Column '{col}' does not exist in the DataFrame.\")\n",
    "            continue\n",
    "\n",
    "        # Check if column is of type float64\n",
    "        if df[col].dtype != 'float64':\n",
    "            print(f\"Column '{col}' is not of type float64, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Check for NaNs and analyze range\n",
    "        has_nan = df[col].isna().any()\n",
    "        min_val = df[col].min()\n",
    "        max_val = df[col].max()\n",
    "\n",
    "        print(f\"\\nAnalyzing column '{col}':\")\n",
    "        print(f\"  - Min value: {min_val}\")\n",
    "        print(f\"  - Max value: {max_val}\")\n",
    "        print(f\"  - Contains NaNs: {'Yes' if has_nan else 'No'}\")\n",
    "\n",
    "        # Evaluate if casting to float32 is safe\n",
    "        if min_val >= float32_min and max_val <= float32_max:\n",
    "            print(f\"  - Column '{col}' is within float32 range and can be safely cast to float32.\")\n",
    "            # Optional: Cast to float32 if suitable\n",
    "            df[col] = df[col].astype('float32')\n",
    "            print(f\"  - Column '{col}' has been cast to float32.\")\n",
    "        else:\n",
    "            print(f\"  - Column '{col}' has values outside the float32 range. Conversion to float32 is not safe.\")\n",
    "            \n",
    "cast_float32(loans, float64_columns)\n",
    "# Convert columns to datetime type\n",
    "date_columns = [\n",
    "    'issue_d', 'earliest_cr_line', 'last_pymnt_d', 'next_pymnt_d',\n",
    "    'last_credit_pull_d', 'hardship_start_date', 'hardship_end_date',\n",
    "    'payment_plan_start_date', 'debt_settlement_flag_date', 'settlement_date'\n",
    "]\n",
    "for col in date_columns:\n",
    "    loans[col] = pd.to_datetime(loans[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dtype('int64') dtype('float64') dtype('O')]\n"
     ]
    }
   ],
   "source": [
    "column_types = df_loans.dtypes.unique()\n",
    "print(column_types)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de NaNs o missings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maneja los datos de tipos missing. Elije una estrategia adecuada dependiendo del tipo de dato que le asignaste a la columna.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea codigo para **guardar** y **cargar** un archivo JSON en el que se guarde la `estrategia` y `valor` que utilizaste para **imputar**. Por ejemplo: Si hay una columna que se llama `columna 3` y utilizaste la estrategia de imputacion de media, y existe otra llamada `columna 4` y  elegiste la palabra 'missing' el JSON debera contener:  \n",
    "  \n",
    " `{'columna 3':{'estrategia':'mean', 'valor':3.4}, 'columna 4':{'estrategia':'identificador', 'valor':'missing'}}`  \n",
    "\n",
    " De tal manera que para cada columna que tenga un metodo de imputacion apunte a otro diccionario donde el **key** `estrategia` describa de manera sencilla el metodo, y el **key** `valor` el valor usado. En general:   \n",
    " `{'nombre de la columna':{'estrategia':'descripcion de estrategia', 'valor':'valor utilizado'}}`. \n",
    " \n",
    "\n",
    "De utilizar mas de un metodo puedes anidarlos en una lista  \n",
    "  `[{...},{...}]`.  \n",
    "\n",
    "Incluso si la columna utilizada no sufrio imputacion, es necesario que la agregues al JSON.\n",
    "\n",
    "La idea es que cualquier otra persona pueda cargar el el archivo JSON con tu funcion, entender que hiciste y replicarlo facilmente. No existe solo una respuesta correcta, pero tendras que justificar y explicar tus deciciones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu codigo aqui\n",
    "#primero quitamos todas las columnas que solo contengan Nan porque son columnas que no aportan nada de información y ocupan espacio\n",
    "def drop_nan_only_columns(df):\n",
    "    \"\"\"\n",
    "    Drops columns that contain only NaN values.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame from which to drop NaN-only columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with NaN-only columns removed.\n",
    "    \"\"\"\n",
    "    # Drop columns where all values are NaN\n",
    "    df_cleaned = df.dropna(axis=1, how='all')\n",
    "    return df_cleaned\n",
    "\n",
    "# Example usage\n",
    "# Assuming `loans` is your DataFrame\n",
    "loans_cleaned = drop_nan_only_columns(loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle numeric column imputation\n",
    "def imputar_numerico(df, column):\n",
    "    # Use mean or median based on skewness\n",
    "    if abs(df[column].skew()) < 1:\n",
    "        value = df[column].mean()\n",
    "        strategy = 'mean'\n",
    "    else:\n",
    "        value = df[column].median()\n",
    "        strategy = 'median'\n",
    "    df[column].fillna(value)\n",
    "    return {\"columna\":column,\"estrategia\": strategy, \"valor\": value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputar_categorico(df, column):\n",
    "    # Use a placeholder string for missing values\n",
    "    value = \"missing\"\n",
    "    df[column].fillna(value)\n",
    "    return { \"estrategia\": \"identificador\", \"valor\": value}\n",
    "# Function to handle date column imputation\n",
    "def imputar_fecha(df, column):\n",
    "    # Use a placeholder date for missing values\n",
    "    value = pd.Timestamp(\"1900-01-01\")\n",
    "    df[column].fillna(value)\n",
    "    return {\"estrategia\": \"placeholder_date\", \"valor\": str(value)}\n",
    "# Function to handle boolean column imputation\n",
    "def imputar_booleano(df, column):\n",
    "    # Use False as the default for missing values\n",
    "    value = False\n",
    "    df[column].fillna(value)\n",
    "    return {\"estrategia\": \"default_bool\", \"valor\": value}\n",
    "# Main function to apply imputations based on data type\n",
    "def imputar_valores(df):\n",
    "    imputation_strategies = {}\n",
    "    for column in df.columns:\n",
    "        if df[column].isna().sum() > 0:\n",
    "            print(\"woo\")\n",
    "            if pd.api.types.is_numeric_dtype(df[column]):\n",
    "                imputation_strategies[column] = imputar_numerico(df, column)\n",
    "            elif pd.api.types.is_object_dtype(df[column]):\n",
    "                imputation_strategies[column] = imputar_categorico(df, column)\n",
    "            elif pd.api.types.is_datetime64_any_dtype(df[column]):\n",
    "                imputation_strategies[column] = imputar_fecha(df, column)\n",
    "            elif pd.api.types.is_bool_dtype(df[column]):\n",
    "                imputation_strategies[column] = imputar_booleano(df, column)\n",
    "        else:\n",
    "            imputation_strategies[column] = {\"estrategia\": \"sin_imputacion\", \"valor\": None}\n",
    "    return imputation_strategies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_strategies = {\n",
    "    \"mean\": \"Replaces NaN values with the mean of the column for balanced data.\",\n",
    "    \"median\": \"Replaces NaN values with the median of the column for skewed data.\",\n",
    "    \"identificador\": \"Replaces NaN values in categorical columns with a placeholder like 'missing'.\",\n",
    "    \"placeholder_date\": \"Replaces NaN values in date columns with a default date (e.g., '1900-01-01').\",\n",
    "    \"default_bool\": \"Replaces NaN values in boolean columns with a default False value.\",\n",
    "    \"sin_imputacion\": \"Indicates no imputation was needed because no NaN values were present.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n",
      "woo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37450/669493270.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column].fillna(value, inplace=True)\n",
      "/tmp/ipykernel_37450/669493270.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(value, inplace=True)\n",
      "/tmp/ipykernel_37450/669493270.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(value, inplace=True)\n",
      "/tmp/ipykernel_37450/669493270.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column].fillna(value, inplace=True)\n",
      "/tmp/ipykernel_37450/669493270.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(value, inplace=True)\n",
      "/tmp/ipykernel_37450/669493270.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column].fillna(value, inplace=True)\n",
      "/tmp/ipykernel_37450/669493270.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(value, inplace=True)\n",
      "/tmp/ipykernel_37450/669493270.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column].fillna(value, inplace=True)\n",
      "/tmp/ipykernel_37450/669493270.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(value, inplace=True)\n",
      "/tmp/ipykernel_37450/669493270.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column].fillna(value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def imputar_numerico(df, column):\n",
    "\t# Use mean or median based on skewness\n",
    "\tif abs(df[column].skew()) < 1:\n",
    "\t\tvalue = df[column].mean()\n",
    "\t\tstrategy = 'mean'\n",
    "\telse:\n",
    "\t\tvalue = df[column].median()\n",
    "\t\tstrategy = 'median'\n",
    "\t\n",
    "\t# Ensure the value matches the column's data type\n",
    "\tif pd.api.types.is_integer_dtype(df[column]):\n",
    "\t\tvalue = int(value)\n",
    "\telif pd.api.types.is_float_dtype(df[column]):\n",
    "\t\tvalue = float(value)\n",
    "\t\n",
    "\tdf[column].fillna(value, inplace=True)\n",
    "\treturn {\"columna\": column, \"estrategia\": strategy, \"valor\": value}\n",
    "\n",
    "imputation_strategies = imputar_valores(loans_cleaned)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codigo para salvar y cargar JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Save imputation strategies to JSON\n",
    "with open(\"imputation_strategies.json\", \"w\") as file:\n",
    "    json.dump(imputation_strategies, file, indent=4)\n",
    "\n",
    "# Save strategy explanations to JSON\n",
    "with open(\"strategy_explanations.json\", \"w\") as file:\n",
    "    json.dump(explanation_strategies, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation Strategies:\n",
      " {'Unnamed: 0': {'estrategia': 'sin_imputacion', 'valor': None}, 'id': {'estrategia': 'sin_imputacion', 'valor': None}, 'loan_amnt': {'estrategia': 'sin_imputacion', 'valor': None}, 'funded_amnt': {'estrategia': 'sin_imputacion', 'valor': None}, 'funded_amnt_inv': {'estrategia': 'sin_imputacion', 'valor': None}, 'term': {'estrategia': 'sin_imputacion', 'valor': None}, 'int_rate': {'estrategia': 'sin_imputacion', 'valor': None}, 'installment': {'estrategia': 'sin_imputacion', 'valor': None}, 'grade': {'estrategia': 'sin_imputacion', 'valor': None}, 'sub_grade': {'estrategia': 'sin_imputacion', 'valor': None}, 'home_ownership': {'estrategia': 'sin_imputacion', 'valor': None}, 'annual_inc': {'estrategia': 'sin_imputacion', 'valor': None}, 'verification_status': {'estrategia': 'sin_imputacion', 'valor': None}, 'issue_d': {'estrategia': 'sin_imputacion', 'valor': None}, 'loan_status': {'estrategia': 'sin_imputacion', 'valor': None}, 'pymnt_plan': {'estrategia': 'sin_imputacion', 'valor': None}, 'purpose': {'estrategia': 'sin_imputacion', 'valor': None}, 'title': {'estrategia': 'sin_imputacion', 'valor': None}, 'zip_code': {'estrategia': 'sin_imputacion', 'valor': None}, 'addr_state': {'estrategia': 'sin_imputacion', 'valor': None}, 'dti': {'estrategia': 'sin_imputacion', 'valor': None}, 'delinq_2yrs': {'estrategia': 'sin_imputacion', 'valor': None}, 'earliest_cr_line': {'estrategia': 'sin_imputacion', 'valor': None}, 'fico_range_low': {'estrategia': 'sin_imputacion', 'valor': None}, 'fico_range_high': {'estrategia': 'sin_imputacion', 'valor': None}, 'inq_last_6mths': {'estrategia': 'sin_imputacion', 'valor': None}, 'mths_since_last_delinq': {'columna': 'mths_since_last_delinq', 'estrategia': 'mean', 'valor': 33}, 'mths_since_last_record': {'columna': 'mths_since_last_record', 'estrategia': 'mean', 'valor': 69}, 'open_acc': {'estrategia': 'sin_imputacion', 'valor': None}, 'pub_rec': {'estrategia': 'sin_imputacion', 'valor': None}, 'revol_bal': {'estrategia': 'sin_imputacion', 'valor': None}, 'revol_util': {'columna': 'revol_util', 'estrategia': 'mean', 'valor': 55.43498992919922}, 'total_acc': {'estrategia': 'sin_imputacion', 'valor': None}, 'initial_list_status': {'estrategia': 'sin_imputacion', 'valor': None}, 'out_prncp': {'estrategia': 'sin_imputacion', 'valor': None}, 'out_prncp_inv': {'estrategia': 'sin_imputacion', 'valor': None}, 'total_pymnt': {'estrategia': 'sin_imputacion', 'valor': None}, 'total_pymnt_inv': {'estrategia': 'sin_imputacion', 'valor': None}, 'total_rec_prncp': {'estrategia': 'sin_imputacion', 'valor': None}, 'total_rec_int': {'estrategia': 'sin_imputacion', 'valor': None}, 'total_rec_late_fee': {'estrategia': 'sin_imputacion', 'valor': None}, 'recoveries': {'estrategia': 'sin_imputacion', 'valor': None}, 'collection_recovery_fee': {'estrategia': 'sin_imputacion', 'valor': None}, 'last_pymnt_d': {'estrategia': 'placeholder_date', 'valor': '1900-01-01 00:00:00'}, 'last_pymnt_amnt': {'estrategia': 'sin_imputacion', 'valor': None}, 'next_pymnt_d': {'estrategia': 'placeholder_date', 'valor': '1900-01-01 00:00:00'}, 'last_credit_pull_d': {'estrategia': 'placeholder_date', 'valor': '1900-01-01 00:00:00'}, 'last_fico_range_high': {'estrategia': 'sin_imputacion', 'valor': None}, 'last_fico_range_low': {'estrategia': 'sin_imputacion', 'valor': None}, 'collections_12_mths_ex_med': {'estrategia': 'sin_imputacion', 'valor': None}, 'mths_since_last_major_derog': {'columna': 'mths_since_last_major_derog', 'estrategia': 'mean', 'valor': 43}, 'policy_code': {'estrategia': 'sin_imputacion', 'valor': None}, 'application_type': {'estrategia': 'sin_imputacion', 'valor': None}, 'acc_now_delinq': {'estrategia': 'sin_imputacion', 'valor': None}, 'tot_coll_amt': {'estrategia': 'sin_imputacion', 'valor': None}, 'tot_cur_bal': {'estrategia': 'sin_imputacion', 'valor': None}, 'total_rev_hi_lim': {'estrategia': 'sin_imputacion', 'valor': None}, 'acc_open_past_24mths': {'estrategia': 'sin_imputacion', 'valor': None}, 'avg_cur_bal': {'estrategia': 'sin_imputacion', 'valor': None}, 'bc_open_to_buy': {'columna': 'bc_open_to_buy', 'estrategia': 'median', 'valor': 3844}, 'bc_util': {'columna': 'bc_util', 'estrategia': 'mean', 'valor': 64.56002044677734}, 'chargeoff_within_12_mths': {'estrategia': 'sin_imputacion', 'valor': None}, 'delinq_amnt': {'estrategia': 'sin_imputacion', 'valor': None}, 'mo_sin_old_il_acct': {'columna': 'mo_sin_old_il_acct', 'estrategia': 'mean', 'valor': 127}, 'mo_sin_old_rev_tl_op': {'estrategia': 'sin_imputacion', 'valor': None}, 'mo_sin_rcnt_rev_tl_op': {'estrategia': 'sin_imputacion', 'valor': None}, 'mo_sin_rcnt_tl': {'estrategia': 'sin_imputacion', 'valor': None}, 'mort_acc': {'estrategia': 'sin_imputacion', 'valor': None}, 'mths_since_recent_bc': {'columna': 'mths_since_recent_bc', 'estrategia': 'median', 'valor': 13}, 'mths_since_recent_bc_dlq': {'columna': 'mths_since_recent_bc_dlq', 'estrategia': 'mean', 'valor': 39}, 'mths_since_recent_inq': {'columna': 'mths_since_recent_inq', 'estrategia': 'mean', 'valor': 6}, 'mths_since_recent_revol_delinq': {'columna': 'mths_since_recent_revol_delinq', 'estrategia': 'mean', 'valor': 35}, 'num_accts_ever_120_pd': {'estrategia': 'sin_imputacion', 'valor': None}, 'num_actv_bc_tl': {'estrategia': 'sin_imputacion', 'valor': None}, 'num_actv_rev_tl': {'estrategia': 'sin_imputacion', 'valor': None}, 'num_bc_sats': {'estrategia': 'sin_imputacion', 'valor': None}, 'num_bc_tl': {'estrategia': 'sin_imputacion', 'valor': None}, 'num_il_tl': {'estrategia': 'sin_imputacion', 'valor': None}, 'num_op_rev_tl': {'estrategia': 'sin_imputacion', 'valor': None}, 'num_rev_accts': {'estrategia': 'sin_imputacion', 'valor': None}, 'num_rev_tl_bal_gt_0': {'estrategia': 'sin_imputacion', 'valor': None}, 'num_sats': {'estrategia': 'sin_imputacion', 'valor': None}, 'num_tl_120dpd_2m': {'columna': 'num_tl_120dpd_2m', 'estrategia': 'median', 'valor': 0}, 'num_tl_30dpd': {'estrategia': 'sin_imputacion', 'valor': None}, 'num_tl_90g_dpd_24m': {'estrategia': 'sin_imputacion', 'valor': None}, 'num_tl_op_past_12m': {'estrategia': 'sin_imputacion', 'valor': None}, 'pct_tl_nvr_dlq': {'estrategia': 'sin_imputacion', 'valor': None}, 'percent_bc_gt_75': {'columna': 'percent_bc_gt_75', 'estrategia': 'mean', 'valor': 50.6947021484375}, 'pub_rec_bankruptcies': {'estrategia': 'sin_imputacion', 'valor': None}, 'tax_liens': {'estrategia': 'sin_imputacion', 'valor': None}, 'tot_hi_cred_lim': {'estrategia': 'sin_imputacion', 'valor': None}, 'total_bal_ex_mort': {'estrategia': 'sin_imputacion', 'valor': None}, 'total_bc_limit': {'estrategia': 'sin_imputacion', 'valor': None}, 'total_il_high_credit_limit': {'estrategia': 'sin_imputacion', 'valor': None}, 'hardship_flag': {'estrategia': 'sin_imputacion', 'valor': None}, 'deferral_term': {'columna': 'deferral_term', 'estrategia': 'mean', 'valor': 3}, 'hardship_amount': {'columna': 'hardship_amount', 'estrategia': 'mean', 'valor': 110.3355712890625}, 'hardship_start_date': {'estrategia': 'placeholder_date', 'valor': '1900-01-01 00:00:00'}, 'hardship_end_date': {'estrategia': 'placeholder_date', 'valor': '1900-01-01 00:00:00'}, 'payment_plan_start_date': {'estrategia': 'placeholder_date', 'valor': '1900-01-01 00:00:00'}, 'hardship_length': {'columna': 'hardship_length', 'estrategia': 'mean', 'valor': 3}, 'hardship_dpd': {'columna': 'hardship_dpd', 'estrategia': 'mean', 'valor': 14}, 'orig_projected_additional_accrued_interest': {'columna': 'orig_projected_additional_accrued_interest', 'estrategia': 'mean', 'valor': 323.4951171875}, 'hardship_payoff_balance_amount': {'columna': 'hardship_payoff_balance_amount', 'estrategia': 'mean', 'valor': 8046.6162109375}, 'hardship_last_payment_amount': {'columna': 'hardship_last_payment_amount', 'estrategia': 'mean', 'valor': 186.5631561279297}, 'disbursement_method': {'estrategia': 'sin_imputacion', 'valor': None}, 'debt_settlement_flag': {'estrategia': 'sin_imputacion', 'valor': None}, 'debt_settlement_flag_date': {'estrategia': 'placeholder_date', 'valor': '1900-01-01 00:00:00'}, 'settlement_date': {'estrategia': 'placeholder_date', 'valor': '1900-01-01 00:00:00'}, 'settlement_amount': {'columna': 'settlement_amount', 'estrategia': 'median', 'valor': 3881.1201171875}, 'settlement_percentage': {'columna': 'settlement_percentage', 'estrategia': 'mean', 'valor': 47.72052001953125}, 'settlement_term': {'columna': 'settlement_term', 'estrategia': 'mean', 'valor': 8}}\n",
      "\n",
      "Strategy Explanations:\n",
      " {'mean': 'Replaces NaN values with the mean of the column for balanced data.', 'median': 'Replaces NaN values with the median of the column for skewed data.', 'identificador': \"Replaces NaN values in categorical columns with a placeholder like 'missing'.\", 'placeholder_date': \"Replaces NaN values in date columns with a default date (e.g., '1900-01-01').\", 'default_bool': 'Replaces NaN values in boolean columns with a default False value.', 'sin_imputacion': 'Indicates no imputation was needed because no NaN values were present.'}\n"
     ]
    }
   ],
   "source": [
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Load the JSON containing imputation strategies for each column\n",
    "imputation_strategies = load_json(\"imputation_strategies.json\")\n",
    "print(\"Imputation Strategies:\\n\", imputation_strategies)\n",
    "\n",
    "# Load the JSON containing explanations of each strategy\n",
    "strategy_explanations = load_json(\"strategy_explanations.json\")\n",
    "print(\"\\nStrategy Explanations:\\n\", strategy_explanations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
