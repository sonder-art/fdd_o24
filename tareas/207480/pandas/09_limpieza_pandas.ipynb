{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediccion de Default en Prestamos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este proyecto utilizaremos un sample de los datos de Lending Club. La idea es predecir si cierto usuario cometera Default basado en informacion que la plataforma recolecta. Esto nos ayudara a mejorar la metodologia/pipeline de prestamo.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripcion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Contiene los prestamos de esta plataforma:\n",
    "\n",
    "    periodo 2007-2017Q3.\n",
    "    887mil observaciones, sample de 100mil\n",
    "    150 variables\n",
    "    Target: loan status\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar un ETL y un EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Limpia los datos de tal manera que al final del ETL queden en formato `tidy`.\n",
    "1. Asegurate de cargar y leer los datos\n",
    "2. Crea una tabla donde se guarde el nombre de la columna y el tipo de dato: (`column_name`,   `type`).\n",
    "3. Asegurate de pensar cual es el tipo de dato correcto. Porque elejiste strig/object o float o int?. No hay respuestas incorrectas como tal, pero tienes que justificar tu decision.\n",
    "4. Maneja missings o nans de la manera adecuada. Justifica cada decision\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Preparar lo datos para un pipeline de datos\n",
    "1. Quitar columnas inservibles \n",
    "2. Imputar valores\n",
    "3. Mantener replicabildiad y reproducibilidad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No olvides anotar tus justificaciones en celdas para recordar cuando te toque explicarlo.** Puedes agregar el numero de celdas que necesites para poner tu explicacion y el codigo, solo manten la estructura."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vas a obtener 2 errores, solucionalo con los visto en clase.  \n",
    "Tip: Se arreglan con argumentos adicionales de la funcion `read_csv`  \n",
    "Documentacion: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo esta comprimido, le ponemos el parametro al read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42550/4019059519.py:1: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  loans = pd.read_csv('https://github.com/sonder-art/fdd_prim_2023/blob/main/codigo/pandas/LoansData_sample.csv.gz?raw=true', compression='gzip')\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv('https://github.com/sonder-art/fdd_prim_2023/blob/main/codigo/pandas/LoansData_sample.csv.gz?raw=true', compression='gzip')\n",
    "#print and see:\n",
    "#loans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla (column_name, type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisa el metodo pd.DataFrame.dtypes. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                 int64\n",
       "id                         int64\n",
       "member_id                float64\n",
       "loan_amnt                float64\n",
       "funded_amnt              float64\n",
       "                          ...   \n",
       "settlement_status         object\n",
       "settlement_date           object\n",
       "settlement_amount        float64\n",
       "settlement_percentage    float64\n",
       "settlement_term          float64\n",
       "Length: 151, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_types =loans.dtypes\n",
    "column_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar descripcion de columnas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente tabla tiene una descripcion del significado de cada columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuve que instalar openpyxl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "datos_dict = pd.read_excel(\n",
    "    'https://resources.lendingclub.com/LCDataDictionary.xlsx')\n",
    "datos_dict.columns = ['feature', 'description']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reordenar para que esten en mismo orden que el df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'loans' is your DataFrame\n",
    "loans_columns = loans.columns.tolist()  # Get the list of columns from the loans DataFrame\n",
    "\n",
    "# Reorder datos_dict based on the columns in loans\n",
    "# We will filter out features that are not in loans_columns\n",
    "ordered_dict = datos_dict[datos_dict['feature'].isin(loans_columns)].copy()\n",
    "ordered_dict = ordered_dict.set_index('feature').reindex(loans_columns).reset_index()\n",
    "\n",
    "# Display the ordered table\n",
    "#print(ordered_dict)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea codigo para **guardar** y **cargar** el DataFrame de `datos_dict` creada en las celdas anteriores en formato **pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COdigo guardar\n",
    "datos_dict.to_pickle('ordered_dict.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codigo para cargar\n",
    "datos_dict_loaded = pd.read_pickle('ordered_dict.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realiza las transformaciones o casteos (casting) que creas necesarios a tus datos de tal manera que el typo de dato sea adecuado. Al terminar recrea la tabla `column_types` con los nuevos tipos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No olvides anotar tus justificaciones para recordar cuando te toque explicarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unnamed0, esta columna es identica al indice del dataframe, asi que la vamos a eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejos de Unnamed 0\n",
    "loans = loans.drop(columns=['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El term lo cambiaremos a numero, quitamos months y solo dejamos 36 o 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_42550/4179978830.py:9: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  loans['term'] = loans['term'].str.extract('(\\d+)').astype(int)\n"
     ]
    }
   ],
   "source": [
    "#term\n",
    "# Get unique values from a specific column (e.g., 'id')\n",
    "unique_ids = loans['term'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "#print(unique_ids)\n",
    "\n",
    "# Assuming your DataFrame is named 'loans' and the column is named 'term', extraemos solo numero y casteamos a int.\n",
    "loans['term'] = loans['term'].str.extract('(\\d+)').astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos grades y sub_grades a category, ya que son categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grades y subgrades\n",
    "sorted_unique_grades = sorted(loans['grade'].unique())\n",
    "sorted_unique_sub_grades = sorted(loans['sub_grade'].unique())\n",
    "\n",
    "#print(\"Sorted Unique grades:\", sorted_unique_grades)\n",
    "#print(\"Sorted Unique sub_grades:\", sorted_unique_sub_grades)\n",
    "\n",
    "# Cast the columns to 'category' dtype\n",
    "loans['grade'] = loans['grade'].astype('category')\n",
    "loans['sub_grade'] = loans['sub_grade'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emp_title a string, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emp_title\n",
    "# Get unique values from the 'emp_title' column\n",
    "unique_titles = loans['emp_title'].unique()\n",
    "\n",
    "# Convert to list and print\n",
    "unique_titles_list = unique_titles.tolist()\n",
    "#print(unique_titles_list)\n",
    "\n",
    "loans['emp_title'] = loans['emp_title'].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emp_length\n",
    "Notar la descripcion                                   emp_length                                                                                                         \n",
    "Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years. \n",
    "Asi que cambiaremos a numerico como lo indica la descripcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42550/228502096.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  loans['emp_length'] = loans['emp_length'].replace(length_mapping)\n"
     ]
    }
   ],
   "source": [
    "unique_titles = loans['emp_length'].unique()\n",
    "\n",
    "# Convert to list and print\n",
    "unique_titles_list = unique_titles.tolist()\n",
    "#print(unique_titles_list)\n",
    "\n",
    "# Create a mapping dictionary for the replacements\n",
    "length_mapping = {\n",
    "    '10+ years': 10,\n",
    "    '< 1 year': 0,\n",
    "    '1 year': 1,\n",
    "    '2 years': 2,\n",
    "    '3 years': 3,\n",
    "    '4 years': 4,\n",
    "    '5 years': 5,\n",
    "    '6 years': 6,\n",
    "    '7 years': 7,\n",
    "    '8 years': 8,\n",
    "    '9 years': 9\n",
    "}\n",
    "\n",
    "# Replace the values in the emp_length column using the mapping\n",
    "loans['emp_length'] = loans['emp_length'].replace(length_mapping)\n",
    "\n",
    "# Convert to integer type, preserving NaNs\n",
    "loans['emp_length'] = loans['emp_length'].astype('Int64')  # 'Int64' allows for NaN values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "home_ownership\n",
    "Descripcion dice Our values are: RENT, OWN, MORTGAGE, OTHER\n",
    "Cambiamos any a other\n",
    "Convertimos a categorial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_titles = loans['home_ownership'].unique()\n",
    "\n",
    "# Convert to list and print\n",
    "unique_titles_list = unique_titles.tolist()\n",
    "#print(unique_titles_list)\n",
    "\n",
    "# Replace 'ANY' with 'OTHER' in the 'home_ownership' column\n",
    "loans['home_ownership'] = loans['home_ownership'].replace('ANY', 'OTHER')\n",
    "\n",
    "# Convert the 'home_ownership' column to categorical type\n",
    "loans['home_ownership'] = loans['home_ownership'].astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification status, cambiamos a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in the 'verification_status' column\n",
    "unique_verification_status = loans['verification_status'].unique()\n",
    "#print(\"Unique values in 'verification_status':\", unique_verification_status)\n",
    "\n",
    "# Convert the 'verification_status' column to categorical type\n",
    "loans['verification_status'] = loans['verification_status'].astype('category')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "issue_d, cambiamos a timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming loans is your DataFrame\n",
    "loans['issue_d'] = pd.to_datetime(loans['issue_d'], format='%b-%Y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loan_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_loan_status = loans['loan_status'].unique()\n",
    "#print(unique_loan_status)\n",
    "\n",
    "loans['loan_status'] = loans['loan_status'].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pymnt_plan solo tiene y, n; lo haremos boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "unique_loan_status = loans['pymnt_plan'].unique()\n",
    "print(unique_loan_status)\n",
    "\n",
    "loans['pymnt_plan'] = loans['pymnt_plan'].map({'n': False, 'y': True})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desc,  title son descripciones. zip, purpose y addr categorias; purpose (A category provided by the borrower for the loan request.),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data types\n",
    "loans['desc'] = loans['desc'].astype(str)           # Convert 'desc' to string\n",
    "loans['purpose'] = loans['purpose'].astype('category')     # Convert 'purpose' to string\n",
    "loans['title'] = loans['title'].astype(str)         # Convert 'title' to string\n",
    "loans['zip_code'] = loans['zip_code'].astype('category')  # Convert 'zip_code' to categorical\n",
    "loans['addr_state'] = loans['addr_state'].astype('category')  # Convert 'addr_state' to categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "earliest_cr_line, son puras fechas, lo haremos timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['earliest_cr_line'] = pd.to_datetime(loans['earliest_cr_line'], format='%b-%Y', errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial list status, valores solo w o f, a category, boolean no pq no se si w  significa True y f no es False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['initial_list_status'] = loans['initial_list_status'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son fechas, de object a timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['last_pymnt_d'] = pd.to_datetime(loans['last_pymnt_d'], format='%b-%Y', errors='coerce')\n",
    "loans['last_credit_pull_d'] = pd.to_datetime(loans['last_credit_pull_d'], format='%b-%Y', errors='coerce')\n",
    "loans['next_pymnt_d'] = pd.to_datetime(loans['next_pymnt_d'], format='%b-%Y', errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "policy code solo puede tener valores 1 y 2, haremos category\n",
    "Application type igual solo puede tener 2 valores, individual o conjunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['policy_code'] = loans['policy_code'].astype('category')\n",
    "loans['application_type'] = loans['application_type'].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hardship, flag to boolean.\n",
    "type y status a category.\n",
    "Reason quedara object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert hardship_flag to boolean\n",
    "loans['hardship_flag'] = loans['hardship_flag'].map({'N': False, 'Y': True})\n",
    "loans['hardship_status'] = loans['hardship_status'].astype('category')\n",
    "loans['hardship_type'] = loans['hardship_type'].astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A timestamp, son fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['hardship_start_date'] = pd.to_datetime(loans['hardship_start_date'], format='%b-%Y', errors='coerce')\n",
    "loans['hardship_end_date'] = pd.to_datetime(loans['hardship_end_date'], format='%b-%Y', errors='coerce')\n",
    "loans['payment_plan_start_date'] = pd.to_datetime(loans['payment_plan_start_date'], format='%b-%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo los valores unicos y descripciones cambiamos object a su correspondiente en:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert disbursement_method to category\n",
    "loans['disbursement_method'] = loans['disbursement_method'].astype('category')\n",
    "\n",
    "# Convert debt_settlement_flag to boolean\n",
    "loans['debt_settlement_flag'] = loans['debt_settlement_flag'].map({'Y': True, 'N': False})\n",
    "\n",
    "# Convert debt_settlement_flag_date to timestamp\n",
    "loans['debt_settlement_flag_date'] = pd.to_datetime(loans['debt_settlement_flag_date'], format='%b-%Y', errors='coerce')\n",
    "\n",
    "# Convert settlement_status to category\n",
    "loans['settlement_status'] = loans['settlement_status'].astype('category')\n",
    "\n",
    "# Convert settlement_date to timestamp\n",
    "loans['settlement_date'] = pd.to_datetime(loans['settlement_date'], format='%b-%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types =loans.dtypes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de NaNs o missings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maneja los datos de tipos missing. Elije una estrategia adecuada dependiendo del tipo de dato que le asignaste a la columna.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea codigo para **guardar** y **cargar** un archivo JSON en el que se guarde la `estrategia` y `valor` que utilizaste para **imputar**. Por ejemplo: Si hay una columna que se llama `columna 3` y utilizaste la estrategia de imputacion de media, y existe otra llamada `columna 4` y  elegiste la palabra 'missing' el JSON debera contener:  \n",
    "  \n",
    " `{'columna 3':{'estrategia':'mean', 'valor':3.4}, 'columna 4':{'estrategia':'identificador', 'valor':'missing'}}`  \n",
    "\n",
    " De tal manera que para cada columna que tenga un metodo de imputacion apunte a otro diccionario donde el **key** `estrategia` describa de manera sencilla el metodo, y el **key** `valor` el valor usado. En general:   \n",
    " `{'nombre de la columna':{'estrategia':'descripcion de estrategia', 'valor':'valor utilizado'}}`. \n",
    " \n",
    "\n",
    "De utilizar mas de un metodo puedes anidarlos en una lista  \n",
    "  `[{...},{...}]`.  \n",
    "\n",
    "Incluso si la columna utilizada no sufrio imputacion, es necesario que la agregues al JSON.\n",
    "\n",
    "La idea es que cualquier otra persona pueda cargar el el archivo JSON con tu funcion, entender que hiciste y replicarlo facilmente. No existe solo una respuesta correcta, pero tendras que justificar y explicar tus deciciones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncolumnas_con_faltantes = [col for col in loans.columns if loans[col].isna().any()]\\n\\n# Mostrar el resultado\\nif columnas_con_faltantes:\\n    print(\"Las columnas con valores faltantes son:\", columnas_con_faltantes)\\nelse:\\n    print(\"No hay columnas con valores faltantes.\")\\n    \\n# Print unique values for each column\\nfor column in columnas_con_faltantes:\\n    if column in loans.columns:  # Check if the column exists in the DataFrame\\n        unique_values = loans[column].unique()\\n        print(f\"Unique values in \\'{column}\\': {unique_values}\")\\n    else:\\n        print(f\"Column \\'{column}\\' does not exist in the DataFrame.\")\\n# Column to check\\nif columnas_con_faltantes:\\n    X = columnas_con_faltantes[0]\\n\\n    # Get the description from ordered_dict\\n    description = ordered_dict[ordered_dict[\\'feature\\'] == X][\\'description\\'].values[0]\\n\\n    # Get the index position from loans DataFrame columns\\n    try:\\n        column_index = loans.columns.get_loc(X)  # Get index position directly from loans columns\\n        print(f\"Column Index: {column_index}\")\\n    except KeyError:\\n        print(f\"Column \\'{X}\\' does not exist in the DataFrame.\")\\n\\n    # Print description\\n    print(f\"Description: {description}\")\\n\\n    # Print unique values from the specified column in loans DataFrame\\n    if X in loans.columns:  # Check if the column exists before accessing it\\n        unique_values = loans[X].unique()\\n        print(f\"Unique Values in \\'{X}\\': {unique_values}\")\\n    else:\\n        print(f\"Column \\'{X}\\' does not exist in the DataFrame.\")\\n        \\n        \\n    column_types[X]\\n'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checamos todas las columnas con missings or nans y sus descripciones para decidir que hacer con esos missings or Nans\n",
    "# Iterar sobre cada columna y verificar si tiene valores faltantes\n",
    "'''\n",
    "columnas_con_faltantes = [col for col in loans.columns if loans[col].isna().any()]\n",
    "\n",
    "# Mostrar el resultado\n",
    "if columnas_con_faltantes:\n",
    "    print(\"Las columnas con valores faltantes son:\", columnas_con_faltantes)\n",
    "else:\n",
    "    print(\"No hay columnas con valores faltantes.\")\n",
    "    \n",
    "# Print unique values for each column\n",
    "for column in columnas_con_faltantes:\n",
    "    if column in loans.columns:  # Check if the column exists in the DataFrame\n",
    "        unique_values = loans[column].unique()\n",
    "        print(f\"Unique values in '{column}': {unique_values}\")\n",
    "    else:\n",
    "        print(f\"Column '{column}' does not exist in the DataFrame.\")\n",
    "# Column to check\n",
    "if columnas_con_faltantes:\n",
    "    X = columnas_con_faltantes[0]\n",
    "\n",
    "    # Get the description from ordered_dict\n",
    "    description = ordered_dict[ordered_dict['feature'] == X]['description'].values[0]\n",
    "\n",
    "    # Get the index position from loans DataFrame columns\n",
    "    try:\n",
    "        column_index = loans.columns.get_loc(X)  # Get index position directly from loans columns\n",
    "        print(f\"Column Index: {column_index}\")\n",
    "    except KeyError:\n",
    "        print(f\"Column '{X}' does not exist in the DataFrame.\")\n",
    "\n",
    "    # Print description\n",
    "    print(f\"Description: {description}\")\n",
    "\n",
    "    # Print unique values from the specified column in loans DataFrame\n",
    "    if X in loans.columns:  # Check if the column exists before accessing it\n",
    "        unique_values = loans[X].unique()\n",
    "        print(f\"Unique Values in '{X}': {unique_values}\")\n",
    "    else:\n",
    "        print(f\"Column '{X}' does not exist in the DataFrame.\")\n",
    "        \n",
    "        \n",
    "    column_types[X]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos estos solo tienen valores nans, droppeamos la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [column for column in loans.columns if loans[column].isna().all()]\n",
    "\n",
    "# Iterate over each column and drop it if it exists\n",
    "for column in c:\n",
    "    if column in loans.columns:  # Check if the column exists in the DataFrame\n",
    "        loans.drop(columns=[column], inplace=True)  # Drop the column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poner 0 puede interpretarse como algo que hizo, debe, falta, o que ha trabajado, cambiaremos a -1 para evitar complicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to fill with -1\n",
    "amenos1 = [\n",
    "    'emp_length', \n",
    "    'mths_since_last_delinq', \n",
    "    'mths_since_last_record', \n",
    "    'mths_since_last_major_derog', \n",
    "    'mo_sin_old_il_acct', \n",
    "    'mths_since_recent_bc', \n",
    "    'mths_since_recent_bc_dlq', \n",
    "    'mths_since_recent_inq', \n",
    "    'mths_since_recent_revol_delinq'\n",
    "]\n",
    "\n",
    "# Fill NaN values with -1 for each column in the list\n",
    "for col in amenos1:\n",
    "    loans[col] = loans[col].fillna(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "revol_util y bc_util, son un porcentaje, cambiare por 0 si su revol_bal es 0, por la mediana si su revol_bal es distinto de 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When revolving balance is 0, set utilization to 0\n",
    "# For other cases, use median imputation\n",
    "# Define columns and their respective conditions\n",
    "aMediano0 = ['revol_util', 'bc_util']\n",
    "median_values = []\n",
    "\n",
    "for col in aMediano0:\n",
    "    # Calculate the median for the current column, ignoring NaNs\n",
    "    median_value = loans[loans[col].notna()][col].median()\n",
    "    median_values.append(median_value)  # Store median for later use\n",
    "\n",
    "    # Apply the conditions based on the current column\n",
    "    if col == 'revol_util':\n",
    "        loans[col] = loans.apply(\n",
    "            lambda row: 0 if row['revol_bal'] == 0 \n",
    "            else median_value if pd.isna(row[col]) \n",
    "            else row[col], \n",
    "            axis=1\n",
    "        )\n",
    "    elif col == 'bc_util':\n",
    "        loans[col] = loans.apply(\n",
    "            lambda row: 0 if row['bc_open_to_buy'] == 0 \n",
    "            else median_value if pd.isna(row[col]) \n",
    "            else row[col], \n",
    "            axis=1\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estos de timestamps, los cambiare por una fecha que signifique desconocido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using a specific placeholder date\n",
    "aFechaHolder = ['hardship_start_date','last_pymnt_d','next_pymnt_d','last_credit_pull_d','hardship_end_date','payment_plan_start_date',\n",
    "                'debt_settlement_flag_date','settlement_date']\n",
    "placeholder_date = pd.Timestamp('1900-01-01')\n",
    "\n",
    "for i in aFechaHolder:\n",
    "    loans[i] = loans[i].fillna(placeholder_date)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiar valor a 0 no afecta, terminos donde 0 representa nada y no afecta registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "aCero = ['bc_open_to_buy', 'num_tl_120dpd_2m', 'percent_bc_gt_75','deferral_term',\n",
    "         'hardship_amount','hardship_length','hardship_dpd','orig_projected_additional_accrued_interest',\n",
    "         'hardship_payoff_balance_amount','hardship_last_payment_amount','settlement_amount','settlement_percentage',\n",
    "         'settlement_term']\n",
    "\n",
    "for i in aCero:\n",
    "    loans[i] = loans[i].fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorias, cambiaremos NANS por categoria MISSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42550/1800534246.py:8: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(loans[column]):\n"
     ]
    }
   ],
   "source": [
    "# List of columns to update\n",
    "categoriasAMissing = ['hardship_type', 'hardship_reason','hardship_status','hardship_loan_status','settlement_status']\n",
    "\n",
    "# Iterate over each column and update NaN values to 'MISSING'\n",
    "for column in categoriasAMissing:\n",
    "    if column in loans.columns:\n",
    "        # Check if the column is categorical\n",
    "        if pd.api.types.is_categorical_dtype(loans[column]):\n",
    "            # Add 'MISSING' as a category if not already present\n",
    "            if 'MISSING' not in loans[column].cat.categories:\n",
    "                loans[column] = loans[column].cat.add_categories(['MISSING'])\n",
    "        \n",
    "        # Replace NaN values with 'MISSING'\n",
    "        loans[column] = loans[column].fillna('MISSING')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codigo para salvar y cargar JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_imputation_json():\n",
    "    # Prepare the imputation information for JSON\n",
    "    imputation_info = {}\n",
    "\n",
    "    # Document imputation for dropped columns\n",
    "    for column in c:\n",
    "        imputation_info[column] = {\n",
    "            'estrategia': 'Dropeamos columna - todos valores NaN',\n",
    "            'valor': None  # No value since the column is dropped\n",
    "        }\n",
    "        \n",
    "    # Fill imputation info for 'ameno1'\n",
    "    for col in amenos1:\n",
    "        imputation_info[col] = {\n",
    "            'estrategia': 'Indicar que no con identificador negativo, un 0 implicaria cosas',\n",
    "            'valor': -1\n",
    "        }\n",
    "\n",
    "    # Fill imputation info for 'aCero'\n",
    "    for col in aCero:\n",
    "        imputation_info[col] = {\n",
    "            'estrategia': 'Identificador para decir que es nada',\n",
    "            'valor': 0\n",
    "        }\n",
    "\n",
    "    # Fill imputation info for 'placeholder_dates'\n",
    "    for col in aFechaHolder:\n",
    "        imputation_info[col] = {\n",
    "            'estrategia': 'Indicador que no hay fecha registrada',\n",
    "            'valor': '1900-01-01'\n",
    "        }\n",
    "\n",
    "    # Fill imputation info for 'revol_util' and 'bc_util'\n",
    "    for i, col in enumerate(aMediano0):\n",
    "        # Crear una lista para almacenar las estrategias\n",
    "        strategies = []\n",
    "        \n",
    "        # Estrategia: imputaciÃ³n por mediana\n",
    "        strategies.append({\n",
    "            'estrategia': 'median imputation',\n",
    "            'valor': median_values[i]  # Usar la mediana almacenada\n",
    "        })\n",
    "        \n",
    "        # Estrategia: reemplazar 0 con 0\n",
    "        strategies.append({\n",
    "            'estrategia': 'identificador',\n",
    "            'valor': 0\n",
    "        })\n",
    "\n",
    "        # Asignar la lista de estrategias a la clave correspondiente\n",
    "        imputation_info[col] = strategies\n",
    "\n",
    "    # Fill imputation info for 'categorical_missing'\n",
    "    for col in categoriasAMissing:\n",
    "        imputation_info[col] = {\n",
    "            'estrategia': 'Identificador categorico',\n",
    "            'valor': 'MISSING'\n",
    "        }\n",
    "        \n",
    "    all_columns = loans.columns.tolist()#Incluso si la columna utilizada no sufrio imputacion, es necesario que la agregues al JSON.\n",
    "    for col in all_columns:\n",
    "        if col not in imputation_info:\n",
    "            imputation_info[col] = {\n",
    "                'estrategia': 'no imputation',\n",
    "                'valor': None  # O el valor que consideres apropiado\n",
    "            }\n",
    "\n",
    "    # Save to JSON\n",
    "    with open('imputation_strategies.json', 'w') as json_file:\n",
    "        json.dump(imputation_info, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_print_json(file_path):\n",
    "    try:\n",
    "        # Load the JSON file\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            imputation_info = json.load(json_file)\n",
    "\n",
    "        # Print the contents of the JSON file\n",
    "        print(json.dumps(imputation_info, indent=4))  # Pretty print with indentation\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file {file_path} does not exist.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON from the file {file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"member_id\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"annual_inc_joint\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"dti_joint\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"verification_status_joint\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"open_acc_6m\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"open_act_il\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"open_il_12m\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"open_il_24m\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"mths_since_rcnt_il\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"total_bal_il\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"il_util\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"open_rv_12m\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"open_rv_24m\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"max_bal_bc\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"all_util\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"inq_fi\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"total_cu_tl\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"inq_last_12m\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"revol_bal_joint\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"sec_app_fico_range_low\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"sec_app_fico_range_high\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"sec_app_earliest_cr_line\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"sec_app_inq_last_6mths\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"sec_app_mort_acc\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"sec_app_open_acc\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"sec_app_revol_util\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"sec_app_open_act_il\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"sec_app_num_rev_accts\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"sec_app_chargeoff_within_12_mths\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"sec_app_collections_12_mths_ex_med\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"sec_app_mths_since_last_major_derog\": {\n",
      "        \"estrategia\": \"Dropeamos columna - todos valores NaN\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"emp_length\": {\n",
      "        \"estrategia\": \"Indicar que no con identificador negativo, un 0 implicaria cosas\",\n",
      "        \"valor\": -1\n",
      "    },\n",
      "    \"mths_since_last_delinq\": {\n",
      "        \"estrategia\": \"Indicar que no con identificador negativo, un 0 implicaria cosas\",\n",
      "        \"valor\": -1\n",
      "    },\n",
      "    \"mths_since_last_record\": {\n",
      "        \"estrategia\": \"Indicar que no con identificador negativo, un 0 implicaria cosas\",\n",
      "        \"valor\": -1\n",
      "    },\n",
      "    \"mths_since_last_major_derog\": {\n",
      "        \"estrategia\": \"Indicar que no con identificador negativo, un 0 implicaria cosas\",\n",
      "        \"valor\": -1\n",
      "    },\n",
      "    \"mo_sin_old_il_acct\": {\n",
      "        \"estrategia\": \"Indicar que no con identificador negativo, un 0 implicaria cosas\",\n",
      "        \"valor\": -1\n",
      "    },\n",
      "    \"mths_since_recent_bc\": {\n",
      "        \"estrategia\": \"Indicar que no con identificador negativo, un 0 implicaria cosas\",\n",
      "        \"valor\": -1\n",
      "    },\n",
      "    \"mths_since_recent_bc_dlq\": {\n",
      "        \"estrategia\": \"Indicar que no con identificador negativo, un 0 implicaria cosas\",\n",
      "        \"valor\": -1\n",
      "    },\n",
      "    \"mths_since_recent_inq\": {\n",
      "        \"estrategia\": \"Indicar que no con identificador negativo, un 0 implicaria cosas\",\n",
      "        \"valor\": -1\n",
      "    },\n",
      "    \"mths_since_recent_revol_delinq\": {\n",
      "        \"estrategia\": \"Indicar que no con identificador negativo, un 0 implicaria cosas\",\n",
      "        \"valor\": -1\n",
      "    },\n",
      "    \"bc_open_to_buy\": {\n",
      "        \"estrategia\": \"Identificador para decir que es nada\",\n",
      "        \"valor\": 0\n",
      "    },\n",
      "    \"num_tl_120dpd_2m\": {\n",
      "        \"estrategia\": \"Identificador para decir que es nada\",\n",
      "        \"valor\": 0\n",
      "    },\n",
      "    \"percent_bc_gt_75\": {\n",
      "        \"estrategia\": \"Identificador para decir que es nada\",\n",
      "        \"valor\": 0\n",
      "    },\n",
      "    \"deferral_term\": {\n",
      "        \"estrategia\": \"Identificador para decir que es nada\",\n",
      "        \"valor\": 0\n",
      "    },\n",
      "    \"hardship_amount\": {\n",
      "        \"estrategia\": \"Identificador para decir que es nada\",\n",
      "        \"valor\": 0\n",
      "    },\n",
      "    \"hardship_length\": {\n",
      "        \"estrategia\": \"Identificador para decir que es nada\",\n",
      "        \"valor\": 0\n",
      "    },\n",
      "    \"hardship_dpd\": {\n",
      "        \"estrategia\": \"Identificador para decir que es nada\",\n",
      "        \"valor\": 0\n",
      "    },\n",
      "    \"orig_projected_additional_accrued_interest\": {\n",
      "        \"estrategia\": \"Identificador para decir que es nada\",\n",
      "        \"valor\": 0\n",
      "    },\n",
      "    \"hardship_payoff_balance_amount\": {\n",
      "        \"estrategia\": \"Identificador para decir que es nada\",\n",
      "        \"valor\": 0\n",
      "    },\n",
      "    \"hardship_last_payment_amount\": {\n",
      "        \"estrategia\": \"Identificador para decir que es nada\",\n",
      "        \"valor\": 0\n",
      "    },\n",
      "    \"settlement_amount\": {\n",
      "        \"estrategia\": \"Identificador para decir que es nada\",\n",
      "        \"valor\": 0\n",
      "    },\n",
      "    \"settlement_percentage\": {\n",
      "        \"estrategia\": \"Identificador para decir que es nada\",\n",
      "        \"valor\": 0\n",
      "    },\n",
      "    \"settlement_term\": {\n",
      "        \"estrategia\": \"Identificador para decir que es nada\",\n",
      "        \"valor\": 0\n",
      "    },\n",
      "    \"hardship_start_date\": {\n",
      "        \"estrategia\": \"Indicador que no hay fecha registrada\",\n",
      "        \"valor\": \"1900-01-01\"\n",
      "    },\n",
      "    \"last_pymnt_d\": {\n",
      "        \"estrategia\": \"Indicador que no hay fecha registrada\",\n",
      "        \"valor\": \"1900-01-01\"\n",
      "    },\n",
      "    \"next_pymnt_d\": {\n",
      "        \"estrategia\": \"Indicador que no hay fecha registrada\",\n",
      "        \"valor\": \"1900-01-01\"\n",
      "    },\n",
      "    \"last_credit_pull_d\": {\n",
      "        \"estrategia\": \"Indicador que no hay fecha registrada\",\n",
      "        \"valor\": \"1900-01-01\"\n",
      "    },\n",
      "    \"hardship_end_date\": {\n",
      "        \"estrategia\": \"Indicador que no hay fecha registrada\",\n",
      "        \"valor\": \"1900-01-01\"\n",
      "    },\n",
      "    \"payment_plan_start_date\": {\n",
      "        \"estrategia\": \"Indicador que no hay fecha registrada\",\n",
      "        \"valor\": \"1900-01-01\"\n",
      "    },\n",
      "    \"debt_settlement_flag_date\": {\n",
      "        \"estrategia\": \"Indicador que no hay fecha registrada\",\n",
      "        \"valor\": \"1900-01-01\"\n",
      "    },\n",
      "    \"settlement_date\": {\n",
      "        \"estrategia\": \"Indicador que no hay fecha registrada\",\n",
      "        \"valor\": \"1900-01-01\"\n",
      "    },\n",
      "    \"revol_util\": [\n",
      "        {\n",
      "            \"estrategia\": \"median imputation\",\n",
      "            \"valor\": 56.0\n",
      "        },\n",
      "        {\n",
      "            \"estrategia\": \"identificador\",\n",
      "            \"valor\": 0\n",
      "        }\n",
      "    ],\n",
      "    \"bc_util\": [\n",
      "        {\n",
      "            \"estrategia\": \"median imputation\",\n",
      "            \"valor\": 68.7\n",
      "        },\n",
      "        {\n",
      "            \"estrategia\": \"identificador\",\n",
      "            \"valor\": 0\n",
      "        }\n",
      "    ],\n",
      "    \"hardship_type\": {\n",
      "        \"estrategia\": \"Identificador categorico\",\n",
      "        \"valor\": \"MISSING\"\n",
      "    },\n",
      "    \"hardship_reason\": {\n",
      "        \"estrategia\": \"Identificador categorico\",\n",
      "        \"valor\": \"MISSING\"\n",
      "    },\n",
      "    \"hardship_status\": {\n",
      "        \"estrategia\": \"Identificador categorico\",\n",
      "        \"valor\": \"MISSING\"\n",
      "    },\n",
      "    \"hardship_loan_status\": {\n",
      "        \"estrategia\": \"Identificador categorico\",\n",
      "        \"valor\": \"MISSING\"\n",
      "    },\n",
      "    \"settlement_status\": {\n",
      "        \"estrategia\": \"Identificador categorico\",\n",
      "        \"valor\": \"MISSING\"\n",
      "    },\n",
      "    \"id\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"loan_amnt\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"funded_amnt\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"funded_amnt_inv\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"term\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"int_rate\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"installment\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"grade\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"sub_grade\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"emp_title\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"home_ownership\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"annual_inc\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"verification_status\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"issue_d\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"loan_status\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"pymnt_plan\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"desc\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"purpose\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"title\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"zip_code\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"addr_state\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"dti\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"delinq_2yrs\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"earliest_cr_line\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"fico_range_low\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"fico_range_high\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"inq_last_6mths\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"open_acc\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"pub_rec\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"revol_bal\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"total_acc\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"initial_list_status\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"out_prncp\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"out_prncp_inv\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"total_pymnt\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"total_pymnt_inv\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"total_rec_prncp\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"total_rec_int\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"total_rec_late_fee\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"recoveries\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"collection_recovery_fee\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"last_pymnt_amnt\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"last_fico_range_high\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"last_fico_range_low\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"collections_12_mths_ex_med\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"policy_code\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"application_type\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"acc_now_delinq\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"tot_coll_amt\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"tot_cur_bal\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"total_rev_hi_lim\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"acc_open_past_24mths\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"avg_cur_bal\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"chargeoff_within_12_mths\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"delinq_amnt\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"mo_sin_old_rev_tl_op\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"mo_sin_rcnt_rev_tl_op\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"mo_sin_rcnt_tl\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"mort_acc\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"num_accts_ever_120_pd\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"num_actv_bc_tl\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"num_actv_rev_tl\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"num_bc_sats\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"num_bc_tl\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"num_il_tl\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"num_op_rev_tl\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"num_rev_accts\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"num_rev_tl_bal_gt_0\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"num_sats\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"num_tl_30dpd\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"num_tl_90g_dpd_24m\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"num_tl_op_past_12m\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"pct_tl_nvr_dlq\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"pub_rec_bankruptcies\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"tax_liens\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"tot_hi_cred_lim\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"total_bal_ex_mort\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"total_bc_limit\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"total_il_high_credit_limit\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"hardship_flag\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"disbursement_method\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    },\n",
      "    \"debt_settlement_flag\": {\n",
      "        \"estrategia\": \"no imputation\",\n",
      "        \"valor\": null\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "create_imputation_json()\n",
    "load_and_print_json('imputation_strategies.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
